{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"About","text":""},{"location":"#home","title":"Home","text":"<p>For full documentation visit mkdocs.org.</p>"},{"location":"#project-layout","title":"Project layout","text":"<pre><code>mkdocs.yml    # The configuration file.\ndocs/\n    index.md  # The documentation homepage.\n    ...       # Other markdown pages, images and other files.\n</code></pre>"},{"location":"#new-kubernetes-project","title":"New Kubernetes Project","text":"<p>Kubernetes Project</p>"},{"location":"#test-for-github","title":"Test for github","text":""},{"location":"Work%20Projects/","title":"Overview","text":""},{"location":"Work%20Projects/#work-projects","title":"Work Projects","text":""},{"location":"Work%20Projects/cisco-ise/","title":"Cisco ISE Migration","text":""},{"location":"Work%20Projects/cisco-ise/#cisco-ise-migration","title":"Cisco ISE Migration","text":""},{"location":"Work%20Projects/cisco-ise/#context","title":"Context","text":""},{"location":"Work%20Projects/cisco-ise/#tools-used","title":"Tools Used","text":""},{"location":"Work%20Projects/cisco-ise/#architecture","title":"Architecture","text":""},{"location":"Work%20Projects/cisco-ise/#challenges-solutions","title":"Challenges &amp; Solutions","text":""},{"location":"Work%20Projects/cisco-ise/#outcome-metrics","title":"Outcome / Metrics","text":""},{"location":"Work%20Projects/cwautomate/","title":"Automate","text":""},{"location":"Work%20Projects/cwautomate/#connectwise-automate","title":"Connectwise Automate","text":""},{"location":"Work%20Projects/cwautomate/#scripts","title":"Scripts","text":""},{"location":"Work%20Projects/fmc/","title":"Firewall Management Center","text":""},{"location":"Work%20Projects/fmc/#cisco-firewall-managment-center-migration","title":"Cisco Firewall Managment Center Migration","text":""},{"location":"Work%20Projects/fmc/#context","title":"Context","text":""},{"location":"Work%20Projects/fmc/#tools-used","title":"Tools Used","text":""},{"location":"Work%20Projects/fmc/#architecture","title":"Architecture","text":""},{"location":"Work%20Projects/fmc/#challenges-solutions","title":"Challenges &amp; Solutions","text":""},{"location":"Work%20Projects/fmc/#outcome-metrics","title":"Outcome / Metrics","text":""},{"location":"Work%20Projects/mdt/","title":"Microsoft Deployment Toolkit","text":""},{"location":"Work%20Projects/mdt/#microsoft-deployment-toolkit","title":"Microsoft Deployment Toolkit","text":""},{"location":"Work%20Projects/vmwarecloud/","title":"VMware Cloud Migration","text":""},{"location":"Work%20Projects/vmwarecloud/#vmware-cloud-migration","title":"VMware Cloud Migration","text":""},{"location":"Work%20Projects/vmwarecloud/#context","title":"Context","text":""},{"location":"Work%20Projects/vmwarecloud/#tools-used","title":"Tools Used","text":""},{"location":"Work%20Projects/vmwarecloud/#architecture","title":"Architecture","text":""},{"location":"Work%20Projects/vmwarecloud/#challenges-solutions","title":"Challenges &amp; Solutions","text":""},{"location":"Work%20Projects/vmwarecloud/#outcome-metrics","title":"Outcome / Metrics","text":""},{"location":"homelab/","title":"Overview","text":""},{"location":"homelab/#landing-page-overview-diagram","title":"Landing page \u2013 overview + diagram","text":""},{"location":"homelab/#hardware","title":"Hardware","text":"hostname IP Address Notes ryzen01 192.168.1.4 HA Proxmox Cluster with Ceph ryzen02 192.168.1.5 HA Proxmox Cluster with Ceph ryzen03 192.168.1.5 HA Proxmox Cluster with Ceph asus01 192.168.1.31 Proxmox, 4th Ceph Host proxnas prodesk01 prox-test nuc01 nuc02 nuc03 pfsense01"},{"location":"homelab/#virtual-machines","title":"Virtual Machines","text":"VM Name IP Address Note dc01 192.168.50.10 primary domain controller dc02 192.168.50.11 secondary domain controller"},{"location":"homelab/#kubernetes","title":"Kubernetes","text":""},{"location":"homelab/#cicd","title":"CI/CD","text":""},{"location":"homelab/automation/","title":"Overview","text":""},{"location":"homelab/automation/#automation","title":"Automation","text":""},{"location":"homelab/automation/ansible/","title":"Ansible","text":""},{"location":"homelab/automation/ansible/#ansible","title":"Ansible","text":""},{"location":"homelab/automation/terraform/","title":"Terraform","text":""},{"location":"homelab/automation/terraform/#terraform","title":"Terraform","text":""},{"location":"homelab/backups-dr/","title":"Overview","text":""},{"location":"homelab/backups-dr/#backups-and-disaster-recovery","title":"Backups and Disaster Recovery","text":""},{"location":"homelab/backups-dr/pbs/","title":"Proxmox Backup Server","text":""},{"location":"homelab/backups-dr/pbs/#proxmox-backup-server","title":"Proxmox Backup Server","text":""},{"location":"homelab/backups-dr/pbs/#iscsi-to-synology","title":"ISCSI to Synology","text":""},{"location":"homelab/docker/","title":"Overview","text":""},{"location":"homelab/docker/#docker-containers","title":"Docker Containers","text":"<ul> <li>Immich</li> <li>Gitlab </li> <li>Nextcloud</li> </ul>"},{"location":"homelab/docker/nextcloud/","title":"Nextcloud","text":""},{"location":"homelab/docker/nextcloud/#nextcloud","title":"Nextcloud","text":""},{"location":"homelab/identity-security/","title":"Overview","text":""},{"location":"homelab/infrastructure/","title":"Index","text":""},{"location":"homelab/infrastructure/Cisco/","title":"Cisco","text":""},{"location":"homelab/infrastructure/Cisco/#cisco","title":"Cisco","text":""},{"location":"homelab/infrastructure/Proxmox/","title":"Proxmox","text":""},{"location":"homelab/infrastructure/Proxmox/#reinstall-proxmox-and-add-to-existing-cluster","title":"Reinstall Proxmox and Add to Existing Cluster","text":"<ol> <li>First step</li> </ol>"},{"location":"homelab/infrastructure/cloud-server/","title":"Secure Public Linux Cloud Server","text":""},{"location":"homelab/infrastructure/cloud-server/#secure-public-linux-cloud-server","title":"Secure Public Linux Cloud Server","text":"<ol> <li>update the system</li> <li>Lock down SSH config file</li> <li>copy ssh public key to server so you can access it without a password</li> <li>allow ports 443 and 80 with UFW and enable UFW</li> <li>set automatic updates</li> <li>fail2ban</li> </ol>"},{"location":"homelab/infrastructure/cloudflare/","title":"Cloudflare","text":""},{"location":"homelab/infrastructure/cloudflare/#cloudflare","title":"Cloudflare","text":"<ul> <li>used for tunnels to self hosted apps</li> </ul>"},{"location":"homelab/infrastructure/eve-ng/","title":"EVE-NG Lab","text":""},{"location":"homelab/infrastructure/fortigate/","title":"Fortigate","text":""},{"location":"homelab/infrastructure/fortigate/#fortigate","title":"Fortigate","text":""},{"location":"homelab/infrastructure/hardware/","title":"Hardware","text":""},{"location":"homelab/infrastructure/hardware/#hardware","title":"Hardware","text":"<ul> <li>ryzen01</li> <li>ryzen02</li> <li>ryzen03</li> <li>proxnas</li> <li>prodesk01</li> <li>prox-test</li> <li>nuc01</li> <li>nuc02</li> <li>nuc03</li> <li>pfsense01</li> </ul>"},{"location":"homelab/infrastructure/networking/","title":"Pfsense","text":""},{"location":"homelab/infrastructure/samba/","title":"Samba","text":""},{"location":"homelab/infrastructure/samba/#samba","title":"Samba","text":""},{"location":"homelab/infrastructure/samba/#setting-up-samba","title":"Setting up Samba","text":""},{"location":"homelab/infrastructure/samba/#samba-clustering","title":"Samba Clustering","text":"<p>Setup samba cluster on ryzen hosts for cephFS</p>"},{"location":"homelab/infrastructure/storage-ceph/","title":"Ceph","text":""},{"location":"homelab/infrastructure/storage-ceph/#ceph-safe-shutdown","title":"Ceph Safe Shutdown","text":"<p>I kept running into OSD issues because I was just typing reboot on the proxmox CLI. Turns out I need to shut down ceph properly.</p>"},{"location":"homelab/infrastructure/storage-ceph/#1-create-the-script","title":"1. Create the script","text":"<p>Run this on each Ceph node:</p> <pre><code>sudo nano /usr/local/sbin/ceph-safe-reboot\n</code></pre> <p>Paste this:</p> <pre><code>#!/bin/bash\n# ceph-safe-reboot\n# Graceful Ceph reboot helper for Proxmox + Ceph clusters\n# Author: HartDevOps\n\nLOGFILE=\"/var/log/ceph-safe-reboot.log\"\necho \"---- $(date) Starting Ceph Safe Reboot ----\" | tee -a $LOGFILE\n\n# Verify ceph command exists\nif ! command -v ceph &amp;&gt;/dev/null; then\n    echo \"ERROR: ceph command not found. Aborting.\" | tee -a $LOGFILE\n    exit 1\nfi\n\n# 1\ufe0f Set noout flag\necho \"Setting noout flag...\" | tee -a $LOGFILE\nceph osd set noout | tee -a $LOGFILE\n\n# 2\ufe0f Display current cluster health\necho \"Cluster status before shutdown:\" | tee -a $LOGFILE\nceph -s | tee -a $LOGFILE\n\n# 3\ufe0f Stop Ceph services gracefully\necho \"Stopping Ceph services...\" | tee -a $LOGFILE\nsystemctl stop ceph.target\nsleep 5\nsystemctl stop ceph-osd.target ceph-mon.target ceph-mgr.target ceph-mds.target ceph-crash.target 2&gt;/dev/null\n\n# 4\ufe0f Verify services stopped\necho \"Checking Ceph service status...\" | tee -a $LOGFILE\nsystemctl --no-pager --state=running | grep ceph | tee -a $LOGFILE\n\nif systemctl --no-pager --state=running | grep -q ceph; then\n    echo \"Warning: Some Ceph services are still running, waiting 10s...\" | tee -a $LOGFILE\n    sleep 10\n    systemctl stop ceph.target\nfi\n\n# 5\ufe0f Sync disks and flush caches\necho \"Syncing disks...\" | tee -a $LOGFILE\nsync\n\n# 6\ufe0f Log and reboot\necho \"Ceph services stopped. Rebooting now.\" | tee -a $LOGFILE\nsleep 3\nreboot\n</code></pre>"},{"location":"homelab/infrastructure/storage-ceph/#2-make-it-executable","title":"2. Make it executable","text":"<pre><code>sudo chmod +x /usr/local/sbin/ceph-safe-reboot\n</code></pre>"},{"location":"homelab/infrastructure/storage-ceph/#3-usage","title":"3. Usage","text":"<p>Any time you want to reboot a Ceph node:</p> <pre><code>sudo ceph-safe-reboot\n</code></pre> <p>You\u2019ll see output like:</p> <pre><code>---- Fri Oct 25 10:14:33 2025 Starting Ceph Safe Reboot ----\nSetting noout flag...\ncluster status before shutdown:\n  health: HEALTH_OK\nStopping Ceph services...\nSyncing disks...\nCeph services stopped. Rebooting now.\n</code></pre> <p>And it logs every run to:</p> <pre><code>/var/log/ceph-safe-reboot.log\n</code></pre>"},{"location":"homelab/infrastructure/storage-ceph/#ceph-storage-overview","title":"Ceph Storage Overview","text":""},{"location":"homelab/infrastructure/storage-ceph/#architecture","title":"Architecture","text":"<ul> <li>8 OSDs across 4 nodes  </li> <li>4+2 erasure-coded pool for capacity</li> <li>NVMe pool for metadata and WAL/DB</li> </ul>"},{"location":"homelab/infrastructure/storage-ceph/#key-features","title":"Key Features","text":"<ul> <li>CephFS for Kubernetes PVCs</li> <li>RBD images for VM disks</li> <li>Snapshot mirroring + replication</li> </ul>"},{"location":"homelab/infrastructure/storage-ceph/#performance-tuning","title":"Performance Tuning","text":"<ul> <li>OSDs pinned to dedicated NVMe WAL/DB</li> <li>PG count: 256 per pool (tuned for 4+2)</li> <li>Monitors distributed evenly across nodes</li> </ul>"},{"location":"homelab/infrastructure/storage-ceph/#monitoring","title":"Monitoring","text":"<ul> <li>Dashboards via Prometheus + Ceph Exporter</li> <li>Alerts integrated with Alertmanager</li> </ul>"},{"location":"homelab/infrastructure/storage-nas/","title":"NAS","text":""},{"location":"homelab/infrastructure/switches/","title":"Switches","text":""},{"location":"homelab/infrastructure/switches/#switches","title":"Switches","text":""},{"location":"homelab/infrastructure/virtualization/","title":"Overview","text":""},{"location":"homelab/infrastructure/vlans/","title":"VLANS","text":""},{"location":"homelab/infrastructure/vlans/#vlans","title":"Vlans","text":""},{"location":"homelab/infrastructure/wireguard/","title":"Secure Home Access Through VPS and WireGuard","text":""},{"location":"homelab/infrastructure/wireguard/#overview","title":"Overview","text":"<p>The purpose of this is to route traffic to your home network without opening ports on your home router. This specific example was used with Apartment internet which doesnt allow you to port forward any ports. I used it for several months until I moved into my house and got fiber internet. </p> <p>Note</p> <p>I no longer use this and have switched to cloudflare tunnels. I want to keep this documented in case I needed to use it in the future for anything.</p>"},{"location":"homelab/infrastructure/wireguard/#prerequisites","title":"Prerequisites","text":"<ul> <li>A VPS , I used a cheap one from Hetzner </li> <li>Open ports 80, 443, 22, 51820 to your VPS</li> </ul> Hetzner Firewall <ul> <li>Basic Security Settings</li> </ul>"},{"location":"homelab/infrastructure/wireguard/#steps","title":"Steps","text":"<ol> <li>Cloudflare dns points app.example.com to VPS</li> <li>VPS wireguard tunnel to Home Server<ol> <li>forwards 80 and 443 to home server</li> <li>The SSH key to log into the VPS is stored on my macbook.</li> </ol> </li> <li>Home Server runs traefik reverse proxy which sends traffic to Home Server<ol> <li>rule is in file <code>/home/Docker/traefik/conf/rules.yaml</code></li> </ol> </li> <li>Home Server runs Bitwarden</li> </ol>"},{"location":"homelab/infrastructure/wireguard/#install","title":"Install","text":"<p>First, you will want to add the required packages to their repository and then add their repository.</p> <pre><code>sudo apt install software-properties-common\n#Depleted and not necessary as of on Ubuntu only Debian\nsudo add-apt-repository ppa:wireguard/wireguard\n</code></pre> <p>Install wireguard.</p> <pre><code>#both\nsudo apt update \n# to make sure we've indexed the packages on their repo\nsudo apt install wireguard -y\n</code></pre>"},{"location":"homelab/infrastructure/wireguard/#home-server-wg0conf","title":"Home Server wg0.conf","text":"<p>Edit <code>/etc/wireguard/wg0.conf</code> and add the following. Use the command <code>openssl rand -base64 32</code> to generate random strings for the PrivateKey and PublicKey. </p><pre><code>[Interface]\nAddress = 10.1.10.2  # The IP the client should take on connection\n# Generate random key with `openssl rand -base64 32`\nPrivateKey = xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx  # The clients private key\n\n[Peer]\n# Generate random key with `openssl rand -base64 32`\nPublicKey = xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx  # The servers public key\nEndpoint = VPS_Public_IP:51820  # The IP (or hostname) of the server, along with the port WireGuard is listening on\nAllowedIPs = 10.1.10.2/24  # The IPs and masks the client should route through the tunnel\n\nPersistentKeepalive = 25  # Ensure connections remain active, especially useful over NAT\n</code></pre><p></p>"},{"location":"homelab/infrastructure/wireguard/#vps-wg0conf","title":"VPS wg0.conf","text":"<pre><code>[Interface]\nAddress = 10.1.10.1/32\nSaveConfig = true\nPostUp = iptables -A FORWARD -i %i -j ACCEPT; iptables -t nat -A POSTROUTING -o eth0 -j MASQUERADE\nPostDown = iptables -D FORWARD -i %i -j ACCEPT; iptables -t nat -D POSTROUTING -o eth0 -j MASQUERADE\nListenPort = 51820\nPrivateKey = xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \n\n[Peer]\nPublicKey = xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx \nAllowedIPs = 10.1.10.2/32\nEndpoint = Home_Public_IP:41658\n</code></pre>"},{"location":"homelab/infrastructure/wireguard/#autostart-wireguard","title":"Autostart Wireguard","text":"<ol> <li> <p>Add the WireGuard service to systemd:</p> <pre><code>sudo systemctl enable wg-quick@wg0.service\nsudo systemctl daemon-reload\n</code></pre> </li> <li> <p>Start the new service immediately:</p> <pre><code>sudo systemctl start wg-quick@wg0\n</code></pre> </li> <li> <p>Reboot your computer system to verify the automatic connection on startup works as expected.</p> </li> <li> <p>Check the service status:</p> <pre><code>systemctl status wg-quick@wg0\n</code></pre> </li> </ol>"},{"location":"homelab/infrastructure/wireguard/#forwarding-traffic-over-wireguard-to-home-server","title":"Forwarding traffic over Wireguard to Home Server","text":""},{"location":"homelab/infrastructure/wireguard/#sysctl-setup","title":"Sysctl Setup","text":"<p>Now we\u2019ll need to make some changes to our sysctl.conf to allow our VPS to forward using IPtables. Open\u00a0<code>/etc/sysctl.conf</code>\u00a0in your favorite editor.</p> <p>Please find the following line and remove the\u00a0<code>#</code>\u00a0one commenting it out. They should look like the below once done.</p> <pre><code>#VPS\nnet.ipv4.ip_forward=1\n\n#if you wish to IP forward via IPv6 then remove the # from:\nnet.ipv6.conf.all.forwarding=1\n</code></pre> <p>Then we\u2019ll apply that change with the following commands.</p> <pre><code>#VPS\nsudo sysctl -p\nsudo sysctl --system\n</code></pre>"},{"location":"homelab/infrastructure/wireguard/#iptables-setup","title":"IPTables Setup","text":"<p>On our VPS, we\u2019re going to set up some IPtables rules to forward to a reverse proxy running on our home server.</p> <p>Replace eth0 with the public interface of your VPS (found using\u00a0<code>ip a</code>)</p> <pre><code># VPS\n\n# By default drop traffic\nsudo iptables -P FORWARD DROP\n\n# Allow traffic on specified ports\nsudo iptables -A FORWARD -i eth0 -o wg0 -p tcp --syn --dport 80 -m conntrack --ctstate NEW -j ACCEPT\nsudo iptables -A FORWARD -i eth0 -o wg0 -p tcp --syn --dport 443 -m conntrack --ctstate NEW -j ACCEPT\n\n# Allow traffic between wg0 and eth0\nsudo iptables -A FORWARD -i wg0 -o eth0 -m conntrack --ctstate ESTABLISHED,RELATED -j ACCEPT\nsudo iptables -A FORWARD -i wg0 -o eth0 -m conntrack --ctstate ESTABLISHED,RELATED -j ACCEPT\n\n# Forward traffic from eth0 to wg0 on specified ports\nsudo iptables -t nat -A PREROUTING -i eth0 -p tcp --dport 80 -j DNAT --to-destination 10.1.10.2\nsudo iptables -t nat -A PREROUTING -i eth0 -p tcp --dport 443 -j DNAT --to-destination 10.1.10.2\n\n# Forward traffic back to eth0 from wg0 on specified ports\nsudo iptables -t nat -A POSTROUTING -o wg0 -p tcp --dport 80 -d 10.1.10.2 -j SNAT --to-source 10.1.10.1\nsudo iptables -t nat -A POSTROUTING -o wg0 -p tcp --dport 443 -d 10.1.10.2 -j SNAT --to-source 10.1.10.1\n</code></pre>"},{"location":"homelab/infrastructure/wireguard/#persisting-iptables","title":"Persisting IPTables","text":"<p>To have these rules persist through reboots, we\u2019ll need to install netfilter-persistent, use it to save the current configuration, and then enable it.</p> <pre><code># VPS\nsudo apt install netfilter-persistent\nsudo netfilter-persistent save\nsudo systemctl enable netfilter-persistent\n</code></pre> <p>Then we\u2019ll need to use iptables persistent and configure that.</p> <pre><code># VPS\nsudo apt install iptables-persistent\n# hit yes to save the current rules.\n</code></pre>"},{"location":"homelab/infrastructure/hardware/asus01/","title":"asus01","text":""},{"location":"homelab/infrastructure/hardware/asus01/#asus01","title":"asus01","text":"Component Model/Part Number Description Notes Motherboard Supermicro X12DPG-QT6 Dual Socket LGA4189 Supports 3rd Gen Xeon Scalable CPUs CPU Ryzen 5 7600 Memory (RAM) 128GB DDR5 Storage (OS) Delete resource Storage (Data) Delete resource Cache / WAL Delete resource HBA Delete resource Networking 10G NIC Power Supply Delete resource Cooling Delete resource"},{"location":"homelab/infrastructure/hardware/proxnas/","title":"proxnas","text":""},{"location":"homelab/infrastructure/hardware/proxnas/#proxnas","title":"proxnas","text":"Component Model/Part Number Description Notes Motherboard Supermicro X12DPG-QT6 Dual Socket LGA4189 Supports 3rd Gen Xeon Scalable CPUs CPU Ryzen 5 7600 Memory (RAM) 128GB DDR5 Storage (OS) Delete resource Storage (Data) Delete resource Cache / WAL Delete resource HBA Delete resource Networking 10G NIC Power Supply Delete resource Cooling Delete resource"},{"location":"homelab/infrastructure/hardware/ryzen01/","title":"Ryzen01","text":""},{"location":"homelab/infrastructure/hardware/ryzen01/#ryzen01","title":"Ryzen01","text":"Component Model/Part Number Description Notes Motherboard Supermicro X12DPG-QT6 Dual Socket LGA4189 Supports 3rd Gen Xeon Scalable CPUs CPU Ryzen 5 7600 Memory (RAM) 128GB DDR5 Storage (OS) Delete resource Storage (Data) Delete resource Cache / WAL Delete resource HBA Delete resource Networking 10G NIC Power Supply Delete resource Cooling Delete resource Case Delete resource"},{"location":"homelab/infrastructure/hardware/ryzen02/","title":"Ryzen02","text":""},{"location":"homelab/infrastructure/hardware/ryzen02/#ryzen02","title":"Ryzen02","text":"Component Model/Part Number Description Notes Motherboard Supermicro X12DPG-QT6 Dual Socket LGA4189 Supports 3rd Gen Xeon Scalable CPUs CPU Ryzen 5 7600 Memory (RAM) 128GB DDR5 Storage (OS) Delete resource Storage (Data) Delete resource Cache / WAL Delete resource HBA Delete resource Networking 10G NIC Power Supply Delete resource Cooling Delete resource"},{"location":"homelab/infrastructure/hardware/ryzen03/","title":"Ryzen03","text":""},{"location":"homelab/infrastructure/hardware/ryzen03/#ryzen03","title":"Ryzen03","text":"Component Model/Part Number Description Notes Motherboard Supermicro X12DPG-QT6 Dual Socket LGA4189 Supports 3rd Gen Xeon Scalable CPUs CPU Ryzen 5 7600 Memory (RAM) 128GB DDR5 Storage (OS) Delete resource Storage (Data) Delete resource Cache / WAL Delete resource HBA Delete resource Networking 10G NIC Power Supply Delete resource Cooling Delete resource"},{"location":"homelab/kubernetes/","title":"Overview","text":""},{"location":"homelab/kubernetes/#kubernetes","title":"Kubernetes","text":""},{"location":"homelab/kubernetes/#production-cluster","title":"Production Cluster","text":"<p>Talos Linux VMs on proxmox setup for HA. Their VM storage resides on my Ceph NVME pool</p> <ul> <li>3 Control planes, one on each Proxmox Host</li> <li>3 Worker Nodes, one on each Proxmox Host</li> </ul>"},{"location":"homelab/kubernetes/apps/","title":"Apps","text":""},{"location":"homelab/kubernetes/apps/#apps","title":"Apps","text":""},{"location":"homelab/kubernetes/talos/","title":"Talos Linux","text":""},{"location":"homelab/kubernetes/talos/#talos-linux","title":"Talos Linux","text":""},{"location":"homelab/kubernetes/apps/argocd/","title":"Argocd","text":""},{"location":"homelab/kubernetes/apps/argocd/#argocd","title":"Argocd","text":""},{"location":"homelab/kubernetes/apps/argocd/#to-create-new-app","title":"To create new app","text":"<ol> <li>create your app deployment files</li> <li>create an application.yaml file for argocd in the same folder</li> <li>push everything to git</li> <li>k apply -f the application.yaml file</li> <li>wait for app to be created</li> </ol>"},{"location":"homelab/kubernetes/apps/argocd/#create-applicationyaml","title":"Create application.yaml","text":"<pre><code>apiVersion: argoproj.io/v1alpha1\nkind: Application\nmetadata:\n  name: mealie\n  namespace: argocd #keep this as argocd \nspec:\n  project: default\n  source:\n    repoURL: https://gitlab.jhart.tech/jordan/kub-mkdocs.git\n    targetRevision: HEAD\n    path: mealie\n  destination:\n    server: https://kubernetes.default.svc\n    namespace: mealie\n\n  syncPolicy:\n    #syncOptions:\n    #- CreateNamespace=true # create namespace if it doesnt exist \n    automated:\n      selfHeal: true\n      prune: true\n</code></pre>"},{"location":"homelab/kubernetes/apps/argocd/#helm-apps-in-argocd","title":"Helm Apps in Argocd","text":""},{"location":"homelab/monitoring/","title":"Overview","text":""},{"location":"homelab/projects/cloudinit/","title":"Cloudinit","text":""},{"location":"homelab/projects/cloudinit/#goal","title":"Goal","text":"<p>You'll end up with:</p> <ul> <li> <p>A Proxmox VM template called <code>ubuntu-24.04-cloudinit</code></p> </li> <li> <p>Based on the official Ubuntu Cloud image</p> </li> <li> <p>Ready for Terraform (with <code>ciuser</code>, <code>ssh_keys</code>, and networking handled automatically)</p> </li> </ul>"},{"location":"homelab/projects/cloudinit/#step-1-download-the-official-cloud-image","title":"Step 1 -- Download the official cloud image","text":"<p>SSH into your Proxmox node and run:</p> <pre><code>cd /var/lib/vz/template/iso\nwget https://cloud-images.ubuntu.com/noble/current/noble-server-cloudimg-amd64.img\n</code></pre> <p>For Ubuntu 22.04, replace <code>noble</code> with <code>jammy</code>.</p>"},{"location":"homelab/projects/cloudinit/#step-2-create-a-new-vm-to-serve-as-your-template","title":"Step 2 -- Create a new VM to serve as your template","text":"<p>We'll give it basic resources (adjust if needed):</p> <pre><code>VMID=9000\nVMNAME=\"ubuntu-24.04-cloudinit\"\nSTORAGE=\"ceph-ssd\"\n\nqm create $VMID\\\n  --name $VMNAME\\\n  --memory 2048\\\n  --cores 2\\\n  --net0 virtio,bridge=vmbr0\n</code></pre>"},{"location":"homelab/projects/cloudinit/#step-3-import-the-cloud-image-disk","title":"Step 3 -- Import the cloud image disk","text":"<pre><code>qm importdisk $VMID noble-server-cloudimg-amd64.img $STORAGE --format qcow2\n</code></pre> <p>Attach it to the VM:</p> <pre><code>qm set $VMID --scsihw virtio-scsi-pci --scsi0 ${STORAGE}:vm-$VMID-disk-0\n</code></pre>"},{"location":"homelab/projects/cloudinit/#step-4-add-cloud-init-drive","title":"Step 4 -- Add Cloud-Init drive","text":"<p>Add a Cloud-Init device and mark it bootable:</p> <pre><code>qm set $VMID --ide2 ${STORAGE}:cloudinit\nqm set $VMID --boot c --bootdisk scsi0\n</code></pre>"},{"location":"homelab/projects/cloudinit/#step-5-configure-serial-console-for-headless-cloud-images","title":"Step 5 -- Configure serial console (for headless cloud images)","text":"<pre><code>qm set $VMID --serial0 socket --vga serial0\n</code></pre>"},{"location":"homelab/projects/cloudinit/#step-6-set-default-user-ssh-key-optional-now","title":"Step 6 -- Set default user &amp; SSH key (optional now)","text":"<p>If you want to test the template before Terraform:</p> <pre><code>qm set $VMID --ciuser ubuntu\nqm set $VMID --sshkey ~/.ssh/id_rsa.pub\n</code></pre> <p>Terraform will override this later, but it's handy for manual testing.</p>"},{"location":"homelab/projects/cloudinit/#step-7-configure-networking-for-dhcp-default","title":"Step 7 -- Configure networking for DHCP (default)","text":"<p>If your lab uses DHCP on <code>vmbr0</code>, Cloud-Init will grab an IP automatically.\\ If you prefer static IP assignment in Terraform, no change is needed --- you'll pass <code>ipconfig0</code> when cloning.</p>"},{"location":"homelab/projects/cloudinit/#step-8-convert-the-vm-into-a-template","title":"Step 8 -- Convert the VM into a template","text":"<pre><code>qm template $VMID\n</code></pre> <p>Now you have a golden image at <code>9000</code> that Terraform can clone and inject Cloud-Init data into automatically.</p>"},{"location":"homelab/projects/cloudinit/#optional-verify","title":"Optional: verify","text":"<p>To test:</p> <pre><code>qm clone 9000 9100 --name test-ubuntu --full true\nqm set 9100 --ipconfig0 ip=dhcp\nqm start 9100\nqm terminal 9100\n</code></pre> <p>Log in as <code>ubuntu</code> (if you set the key or password) and confirm networking works.</p>"},{"location":"homelab/projects/cloudinit/#summary","title":"Summary","text":"<p>Template specs:</p> Setting Value Name <code>ubuntu-24.04-cloudinit</code> VMID <code>9000</code> Storage <code>local-lvm</code> (adjust as needed) Boot Disk Imported <code>.img</code> Boot Order <code>scsi0</code> Cloud-Init Drive <code>ide2</code> Network <code>virtio</code>, <code>vmbr0</code> Console <code>serial0</code> Status Template"},{"location":"homelab/roadmap/","title":"Overview","text":""},{"location":"notes/","title":"Overview","text":""},{"location":"notes/#notes-landing-page","title":"Notes Landing Page","text":""},{"location":"notes/macos/","title":"macOS","text":""},{"location":"notes/macos/#add-bash-alias-on-mac","title":"Add Bash Alias on Mac","text":"<p>I just open zshrc with sublime, and edit it.</p> <pre><code>subl .zshrc\n</code></pre> <p>And add this on sublime:</p> <pre><code>alias blah=\"/usr/bin/blah\"\n</code></pre> <p>Run this command in terminal:</p> <pre><code>source ~/.zshrc\n</code></pre> <p>Done.</p>"},{"location":"notes/powershell/","title":"Powershell","text":""},{"location":"notes/powershell/#powershell","title":"Powershell","text":""},{"location":"notes/powershell/#scripts","title":"Scripts","text":""},{"location":"notes/ubuntu/","title":"Ubuntu","text":""},{"location":"notes/ubuntu/#ubuntu-notes","title":"Ubuntu Notes","text":"<p>adding more space and extending LVM</p> <pre><code># allocate more space on hypervisor\n# make the partition see the space (dev/sda3, Resize, Write, quit)\nsudo cfdisk\n# extend the physical volume from the partition\nsudo pvresize /dev/sda3\n# extend LV to use up all space from VG\nsudo lvextend -l +100%FREE /dev/ubuntu-vg/ubuntu-lv\n# resize file system\nsudo resize2fs /dev/ubuntu-vg/ubuntu-lv\n# check can see the space on filesystem\ndf -h\n</code></pre>"},{"location":"notes/ubuntu/#remove-ssh-banner","title":"Remove ssh banner","text":"<p>Remove folder <code>/etc/update-motd.d/</code></p>"},{"location":"notes/ubuntu/#set-static-ip","title":"Set Static IP","text":"<p>Edit file <code>/etc/netplan/50-cloud-init.yaml</code></p> <pre><code>network:\n  version: 2\n  renderer: networkd\n  ethernets:\n    ens18:\n      dhcp4: no\n      addresses:\n        - 192.168.1.27/24\n      routes:\n        - to: default\n          via: 192.168.1.1\n      nameservers:\n        addresses: [192.168.1.1]\n</code></pre> <p><code>sudo netplan apply</code></p>"},{"location":"notes/ubuntu/#change-hostname","title":"Change Hostname","text":"<p>Change it in /etc/hosts and /etc/hostname</p>"},{"location":"notes/ubuntu/#install-docker","title":"Install Docker","text":""},{"location":"notes/ubuntu/#add-user","title":"Add User","text":"<p><code>sudo adduser username</code> <code>usermod -aG sudo username</code></p>"},{"location":"notes/ubuntu/#fix-date-and-time","title":"Fix date and time","text":"<p><code>sudo timedatectl set-timezone America/Boise</code></p>"},{"location":"notes/ubuntu/#disable-ipv6","title":"Disable IPV6","text":"<p>I successfully disabled IPv6 once putting the following lines in\u00a0<code>/etc/sysctl.conf</code>:</p> <pre><code>net.ipv6.conf.all.disable_ipv6 = 1\nnet.ipv6.conf.default.disable_ipv6 = 1\nnet.ipv6.conf.lo.disable_ipv6 = 1\n</code></pre> <p>also run this command to load changes</p> <pre><code>sudo sysctl -p\n</code></pre>"},{"location":"notes/ubuntu/#clean-up-disk-space","title":"Clean up disk space","text":"<ul> <li><code>sudo journalctl --vacuum-size=300M</code>\u00a0reduces the logs to 300 MB</li> <li><code>sudo logrotate /etc/logrotate.conf</code>\u00a0compresses or (?) deletes system logs</li> <li><code>sudo apt-get autoremove</code>\u00a0removes software that are only dependencies to packages you removed earlier and don't need anymore</li> <li><code>sudo apt-get clean</code>\u00a0this is nearly the same as\u00a0<code>sudo rm -rf /var/cache/apt/archives/*</code>\u00a0and deletes cached downloaded packages for installation. Running this during some installations could be a problem.</li> </ul>"},{"location":"notes/vim/","title":"Vim","text":""},{"location":"notes/vim/#vim-notes","title":"Vim Notes","text":"<ul> <li>Scroll in terminal - ctrl + B + left bracket with tmux to enter copy mode , ctrl + C to stop </li> <li>Scroll pages with CTRL +D and CTRL + U</li> <li>k run -h | less will pipe the text into the less text reader where you use vim keybinds - :q to quit</li> <li>/ for search in vim</li> <li>n for next search result</li> <li>shift + N for previous search result</li> <li>DD to delete a line</li> <li>o - create new line below current line</li> <li>A - insert at the end of the line</li> <li>shift + V goes into visual mode so you can copy</li> <li>y - yank or copy</li> <li>p - paste </li> <li>u - undo</li> <li>dgg - deletes everything above the cursor</li> <li>pasting yaml into vim - in regular mode :set paste &gt; insert mode &gt; ctrl v = properly formatted yaml</li> <li>r means replace</li> <li>:%s/test/frontend/g - replaces the word test with frontend (find and replace)</li> </ul>"}]}